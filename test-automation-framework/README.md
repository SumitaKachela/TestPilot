# Test Automation Framework

A comprehensive, production-ready test automation framework built with Python, Behave (BDD), Playwright for UI testing, and Requests for API testing.

## ğŸš€ Features

- **BDD Testing**: Behavior-driven development using Behave
- **UI Testing**: Cross-browser testing with Playwright (Chrome, Firefox, Safari)
- **API Testing**: RESTful API testing with Requests library
- **Page Object Model**: Clean, maintainable page object architecture
- **Parallel Execution**: Run tests in parallel for faster execution
- **Multiple Environments**: Support for dev, qa, and staging environments
- **Comprehensive Reporting**: HTML and JSON reports with screenshots
- **Flexible Configuration**: YAML-based configuration management
- **Logging**: Detailed logging with file and console output
- **Data-Driven Testing**: Support for JSON, YAML, CSV, and Excel test data
- **Cross-Platform**: Works on Windows, macOS, and Linux

## ğŸ“ Project Structure

```
test-automation-framework/
â”œâ”€â”€ features/                   # Feature files (BDD scenarios)
â”‚   â”œâ”€â”€ ui/                    # UI test features
â”‚   â”‚   â””â”€â”€ login.feature
â”‚   â””â”€â”€ api/                   # API test features
â”‚       â””â”€â”€ user_management.feature
â”œâ”€â”€ steps/                     # Step definitions
â”‚   â”œâ”€â”€ ui/                    # UI step definitions
â”‚   â”‚   â””â”€â”€ login_steps.py
â”‚   â””â”€â”€ api/                   # API step definitions
â”‚       â””â”€â”€ user_api_steps.py
â”œâ”€â”€ pages/                     # Page object models
â”‚   â””â”€â”€ ui/                    # UI page objects
â”‚       â”œâ”€â”€ base_page.py
â”‚       â”œâ”€â”€ login_page.py
â”‚       â””â”€â”€ dashboard_page.py
â”œâ”€â”€ api/                       # API client modules
â”‚   â”œâ”€â”€ base_api.py
â”‚   â””â”€â”€ user_api.py
â”œâ”€â”€ utility/                   # Utility modules
â”‚   â”œâ”€â”€ common/                # Common utilities
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â”œâ”€â”€ config_reader.py
â”‚   â”‚   â”œâ”€â”€ screenshot_helper.py
â”‚   â”‚   â””â”€â”€ wait_helper.py
â”‚   â””â”€â”€ data_loaders/          # Data loading utilities
â”‚       â””â”€â”€ test_data_loader.py
â”œâ”€â”€ configs/                   # Configuration files
â”‚   â””â”€â”€ environments/
â”‚       â””â”€â”€ config.yaml
â”œâ”€â”€ testdata/                  # Test data files
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â””â”€â”€ login_data.yaml
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ user_data.json
â”œâ”€â”€ reports/                   # Test reports (auto-generated)
â”‚   â”œâ”€â”€ html/
â”‚   â”œâ”€â”€ json/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ screenshots/
â”œâ”€â”€ environment.py             # Behave environment hooks
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ Makefile                   # Make commands for easy execution
â”œâ”€â”€ run.sh                     # Shell script runner (Unix/Linux/macOS)
â”œâ”€â”€ run.bat                    # Batch script runner (Windows)
â””â”€â”€ README.md                  # This file
```

## ğŸ› ï¸ Installation & Setup

### Prerequisites

- Python 3.8 or higher
- pip (Python package manager)

### Quick Setup

1. **Clone or download the framework**
2. **Navigate to the project directory**
   ```bash
   cd test-automation-framework
   ```

3. **Run setup command**
   
   **Using Makefile (Unix/Linux/macOS):**
   ```bash
   make setup
   ```
   
   **Using shell script:**
   ```bash
   ./run.sh setup
   ```
   
   **Using batch script (Windows):**
   ```cmd
   run.bat setup
   ```
   
   **Manual setup:**
   ```bash
   pip install -r requirements.txt
   playwright install
   mkdir -p reports/logs reports/screenshots reports/html reports/json
   ```

## ğŸƒâ€â™‚ï¸ Running Tests

### Using Makefile (Recommended for Unix/Linux/macOS)

```bash
# Run all tests
make test-all

# Run UI tests only
make test-ui

# Run API tests only
make test-api

# Run smoke tests
make test-smoke

# Run tests with specific environment
make test-all TEST_ENV=qa

# Run tests with specific browser
make test-ui BROWSER=firefox

# Run tests in headless mode
make test-headless

# Run tests in parallel
make test-parallel WORKERS=8

# Run tests with specific tags
make test-all TAGS=@login
```

### Using Shell Scripts

**Unix/Linux/macOS:**
```bash
# Run all tests
./run.sh all

# Run UI tests with specific options
./run.sh ui --env=qa --browser=firefox --headless

# Run API tests
./run.sh api --env=stage

# Run smoke tests
./run.sh smoke --tags=@login

# Run tests in parallel
./run.sh all --parallel --workers=8
```

**Windows:**
```cmd
# Run all tests
run.bat all

# Run UI tests with specific options
run.bat ui --env=qa --browser=firefox --headless

# Run API tests
run.bat api --env=stage

# Run smoke tests
run.bat smoke --tags=@login
```

### Using Behave Directly

```bash
# Set environment variables
export TEST_ENV=dev
export BROWSER=chrome
export HEADLESS=false

# Run specific feature
behave features/ui/login.feature

# Run with tags
behave features/ --tags=@smoke

# Run with HTML report
behave features/ --format=html --outfile=reports/html/report.html
```

## ğŸ”§ Configuration

### Environment Configuration

Edit `configs/environments/config.yaml` to configure:

- **Environments**: URLs and settings for dev, qa, staging
- **Browser Settings**: Default browser, headless mode, window size
- **Timeouts**: Page load, element wait, API request timeouts
- **Credentials**: Test user credentials (use environment variables in production)
- **Reporting**: Report formats and options

### Environment Variables

Set these environment variables to override configuration:

```bash
export TEST_ENV=qa          # Test environment (dev|qa|stage)
export BROWSER=firefox      # Browser (chrome|firefox|safari)
export HEADLESS=true        # Headless mode (true|false)
```

## ğŸ“Š Reports

### HTML Reports
- Generated in `reports/html/` directory
- Include test results, screenshots, and execution details
- Open with: `make report` or manually open the HTML file

### JSON Reports
- Generated in `reports/json/` directory
- Machine-readable format for CI/CD integration

### Logs
- Detailed execution logs in `reports/logs/`
- Separate log files for each test run

### Screenshots
- Automatic screenshots on test failures
- Stored in `reports/screenshots/`

## ğŸ·ï¸ Test Tags

Use tags to organize and run specific test subsets:

- `@ui` - UI tests
- `@api` - API tests
- `@smoke` - Smoke tests
- `@regression` - Regression tests
- `@login` - Login-related tests
- `@user` - User management tests
- `@negative` - Negative test cases
- `@crud` - CRUD operation tests

### Running Tests by Tags

```bash
# Run smoke tests
make test-all TAGS=@smoke

# Run login tests
./run.sh all --tags=@login

# Run negative test cases
behave features/ --tags=@negative

# Combine tags (AND)
behave features/ --tags=@ui,@smoke

# Exclude tags
behave features/ --tags=~@slow
```

## ğŸ“ Writing Tests

### Creating Feature Files

Create `.feature` files in the `features/` directory:

```gherkin
Feature: User Registration
  As a new user
  I want to register an account
  So that I can access the application

  @ui @registration @smoke
  Scenario: Successful user registration
    Given I am on the registration page
    When I fill in valid registration details
    And I click the register button
    Then I should see a success message
    And I should receive a confirmation email
```

### Creating Step Definitions

Create step definition files in the `steps/` directory:

```python
from behave import given, when, then
from pages.ui.registration_page import RegistrationPage

@given('I am on the registration page')
def step_navigate_to_registration(context):
    context.registration_page = RegistrationPage(context.page)
    context.registration_page.navigate_to('/register')

@when('I fill in valid registration details')
def step_fill_registration_form(context):
    context.registration_page.fill_registration_form(
        name="John Doe",
        email="john@example.com",
        password="securePassword123"
    )
```

### Creating Page Objects

Create page object classes in the `pages/ui/` directory:

```python
from pages.ui.base_page import BasePage

class RegistrationPage(BasePage):
    # Locators
    NAME_INPUT = "#name"
    EMAIL_INPUT = "#email"
    PASSWORD_INPUT = "#password"
    REGISTER_BUTTON = "#register-btn"
    
    def fill_registration_form(self, name, email, password):
        self.type_text(self.NAME_INPUT, name)
        self.type_text(self.EMAIL_INPUT, email)
        self.type_text(self.PASSWORD_INPUT, password)
        self.click_element(self.REGISTER_BUTTON)
```

### Creating API Clients

Create API client classes in the `api/` directory:

```python
from api.base_api import BaseAPI

class ProductAPI(BaseAPI):
    def __init__(self):
        super().__init__()
        self.products_endpoint = "/api/v1/products"
    
    def create_product(self, product_data):
        response = self.post(self.products_endpoint, json_data=product_data)
        return {
            'response': response,
            'status_code': response.status_code,
            'data': response.json() if response.status_code == 201 else None
        }
```

## ğŸ”„ CI/CD Integration

### GitHub Actions Example

```yaml
name: Test Automation

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        playwright install
    
    - name: Run smoke tests
      run: make test-smoke TEST_ENV=qa HEADLESS=true
    
    - name: Upload test reports
      uses: actions/upload-artifact@v2
      if: always()
      with:
        name: test-reports
        path: reports/
```

### Jenkins Pipeline Example

```groovy
pipeline {
    agent any
    
    environment {
        TEST_ENV = 'qa'
        HEADLESS = 'true'
    }
    
    stages {
        stage('Setup') {
            steps {
                sh 'make setup'
            }
        }
        
        stage('Run Tests') {
            parallel {
                stage('UI Tests') {
                    steps {
                        sh 'make test-ui'
                    }
                }
                stage('API Tests') {
                    steps {
                        sh 'make test-api'
                    }
                }
            }
        }
    }
    
    post {
        always {
            publishHTML([
                allowMissing: false,
                alwaysLinkToLastBuild: true,
                keepAll: true,
                reportDir: 'reports/html',
                reportFiles: '*.html',
                reportName: 'Test Report'
            ])
        }
    }
}
```

## ğŸ› Troubleshooting

### Common Issues

1. **Playwright browsers not installed**
   ```bash
   playwright install
   ```

2. **Permission denied on shell scripts**
   ```bash
   chmod +x run.sh
   ```

3. **Python module not found**
   ```bash
   pip install -r requirements.txt
   ```

4. **Tests failing due to timeouts**
   - Increase timeout values in `configs/environments/config.yaml`
   - Check network connectivity
   - Verify application availability

### Debug Mode

Run tests with verbose logging:

```bash
# Enable debug logging
export LOG_LEVEL=DEBUG
behave features/ --logging-level=DEBUG
```

## ğŸ¤ Contributing

1. Follow the existing code structure and naming conventions
2. Add appropriate tags to new test scenarios
3. Update documentation for new features
4. Ensure all tests pass before submitting changes
5. Use meaningful commit messages

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For questions and support:
1. Check the troubleshooting section
2. Review the example test files
3. Check the configuration files for proper setup
4. Ensure all dependencies are installed correctly

## ğŸ”„ Framework Architecture

### Design Principles

1. **Separation of Concerns**: Clear separation between test logic, page objects, and utilities
2. **DRY (Don't Repeat Yourself)**: Reusable components and utilities
3. **Maintainability**: Easy to update and extend
4. **Scalability**: Supports parallel execution and large test suites
5. **Flexibility**: Configurable for different environments and browsers

### Key Components

- **Environment Hooks**: Setup and teardown logic in `environment.py`
- **Base Classes**: Common functionality in `BasePage` and `BaseAPI`
- **Utilities**: Reusable helpers for logging, configuration, and data loading
- **Configuration Management**: Centralized configuration with environment support
- **Reporting**: Multiple report formats with screenshots and detailed logs

This framework provides a solid foundation for enterprise-grade test automation with best practices and production-ready features.